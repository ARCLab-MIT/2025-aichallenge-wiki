{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastcore.basics import Path, AttrDict\n",
    "from evaluation import NodeDetectionEvaluator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    challenge_dir = Path('../output'),\n",
    "    valid_ratio = 0.1,\n",
    "    lag_steps = 5,\n",
    "    evaluation_tolerance = 6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of feature columns\n",
    "feature_cols = ['Eccentricity', 'Semimajor axis (km)', 'Inclination (deg)', \n",
    "                'RAAN (deg)', 'Argument of periapsis (deg)', 'True anomaly (deg)', \n",
    "                'Latitude (deg)', 'Longitude (deg)', 'Altitude (km)', 'J2k X (km)', \n",
    "                'J2k Y (km)', 'J2k Z (km)', 'J2k Vx (km/s)', 'J2k Vy (km/s)', \n",
    "                'J2k Vz (km/s)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to prepare the data\n",
    "def prepare_data(data_dir, feature_cols, ground_truth=None, lag_steps=1, fill_na=True):\n",
    "    merged_data = pd.DataFrame()\n",
    "    for data_file in Path(data_dir).glob('*.csv'):\n",
    "        data_df = pd.read_csv(data_file)\n",
    "        data_df['ObjectID'] = int(data_file.stem)\n",
    "        data_df['Time Index'] = range(len(data_df))\n",
    "    \n",
    "        lagged_features = []\n",
    "        new_feature_cols = list(feature_cols)  # Create a copy of feature_cols\n",
    "        # Create lagged features for each column in feature_cols\n",
    "        for col in feature_cols:\n",
    "            for i in range(1, lag_steps+1):\n",
    "                lag_col_name = f'{col}_lag_{i}'\n",
    "                data_df[lag_col_name] = data_df.groupby('ObjectID')[col].shift(i)\n",
    "                new_feature_cols.append(lag_col_name)  # Add the lagged feature to new_feature_cols\n",
    "        \n",
    "        # Add the lagged features to the DataFrame all at once\n",
    "        data_df = pd.concat([data_df] + lagged_features, axis=1)\n",
    "\n",
    "        if ground_truth is None:\n",
    "            merged_df = data_df\n",
    "        else:\n",
    "            ground_truth_object = ground_truth[ground_truth['ObjectID'] == data_df['ObjectID'][0]].copy()\n",
    "            # Separate the 'EW' and 'NS' types in the ground truth\n",
    "            ground_truth_EW = ground_truth_object[ground_truth_object['Direction'] == 'EW'].copy()\n",
    "            ground_truth_NS = ground_truth_object[ground_truth_object['Direction'] == 'NS'].copy()\n",
    "            \n",
    "            # Create 'EW' and 'NS' labels and fill 'unknown' values\n",
    "            ground_truth_EW['EW'] = ground_truth_EW['Node'] + '-' + ground_truth_EW['Type']\n",
    "            ground_truth_NS['NS'] = ground_truth_NS['Node'] + '-' + ground_truth_NS['Type']\n",
    "            ground_truth_EW.drop(['Node', 'Type', 'Direction'], axis=1, inplace=True)\n",
    "            ground_truth_NS.drop(['Node', 'Type', 'Direction'], axis=1, inplace=True)\n",
    "\n",
    "            # Merge the input data with the ground truth\n",
    "            merged_df = pd.merge(data_df, \n",
    "                                ground_truth_EW.sort_values('Time Index'), \n",
    "                                on=['Time Index', 'ObjectID'],\n",
    "                                how='left')\n",
    "            merged_df = pd.merge_ordered(merged_df, \n",
    "                                        ground_truth_NS.sort_values('Time Index'), \n",
    "                                        on=['Time Index', 'ObjectID'],\n",
    "                                        how='left')\n",
    "\n",
    "            # Fill 'unknown' values in 'EW' and 'NS' columns that come before the first valid observation\n",
    "            merged_df['EW'].fillna(method='ffill', inplace=True)\n",
    "            merged_df['NS'].fillna(method='ffill', inplace=True)\n",
    "            \n",
    "        merged_data = pd.concat([merged_data, merged_df])\n",
    "\n",
    "    # Fill missing values (for the lagged features)\n",
    "    if fill_na:\n",
    "        merged_data.fillna(method='bfill', inplace=True)\n",
    "    \n",
    "    return merged_data, new_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df['EW'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:47: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df['NS'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df['EW'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:47: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df['NS'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:46: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df['EW'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:47: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_df['NS'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:53: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectID</th>\n",
       "      <th>Time Index</th>\n",
       "      <th>EW</th>\n",
       "      <th>NS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>SS-CK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>SS-CK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ObjectID  Time Index     EW     NS\n",
       "0         5           0  SS-CK  SS-NK\n",
       "1         5           1  SS-CK  SS-NK\n",
       "0         1           0  SS-HK  SS-NK\n",
       "1         1           1  SS-HK  SS-NK\n",
       "0         2           0  SS-NK  SS-NK\n",
       "1         2           1  SS-NK  SS-NK"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the directory paths\n",
    "train_data_dir = config.challenge_dir / \"train_data\"\n",
    "\n",
    "# Load the ground truth data\n",
    "ground_truth = pd.read_csv(config.challenge_dir / 'ground_truth_train.csv')\n",
    "\n",
    "# Apply the function to the ground truth data\n",
    "data, updated_feature_cols = prepare_data(train_data_dir, feature_cols, \n",
    "                                          ground_truth, lag_steps=config.lag_steps)\n",
    "\n",
    "# For each ObjectID, show the first rows of the columns Time Index, ObjectID, EW, and NS\n",
    "data[['ObjectID', 'Time Index' , 'EW', 'NS']].groupby('ObjectID').head(2).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects in the training set: 2\n",
      "Number of objects in the validation set: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a validation set without mixing the ObjectIDs\n",
    "object_ids = data['ObjectID'].unique()\n",
    "train_ids, valid_ids = train_test_split(object_ids, \n",
    "                                        test_size=config.valid_ratio, \n",
    "                                        random_state=42)\n",
    "\n",
    "train_data = data[data['ObjectID'].isin(train_ids)].copy()\n",
    "valid_data = data[data['ObjectID'].isin(valid_ids)].copy()\n",
    "\n",
    "ground_truth_train = ground_truth[ground_truth['ObjectID'].isin(train_ids)].copy()\n",
    "ground_truth_valid = ground_truth[ground_truth['ObjectID'].isin(valid_ids)].copy()\n",
    "\n",
    "# Count the number of objects in the training and validation sets\n",
    "print('Number of objects in the training set:', len(train_data['ObjectID'].unique()))\n",
    "print('Number of objects in the validation set:', len(valid_data['ObjectID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values of EW in test data: set()\n",
      "Missing values of NS in test data: set()\n",
      "Values of EW not present in NS: {'SS-HK', 'AD-NK'}\n"
     ]
    }
   ],
   "source": [
    "# Get the unique values of EW and NS in train and test data\n",
    "train_EW = set(train_data['EW'].unique())\n",
    "train_NS = set(train_data['NS'].unique())\n",
    "test_EW = set(train_data['EW'].unique())\n",
    "test_NS = set(valid_data['NS'].unique())\n",
    "\n",
    "# Get the values of EW and NS that are in test data but not in train data\n",
    "missing_EW = test_EW.difference(train_EW)\n",
    "missing_NS = test_NS.difference(train_NS)\n",
    "\n",
    "# Check if all the values in EW are also present in NS\n",
    "if not set(train_data['EW'].unique()).issubset(set(train_data['NS'].unique())):\n",
    "    # Get the values of EW that are not present in NS\n",
    "    missing_EW_NS = set(train_data['EW'].unique()).difference(\n",
    "        set(train_data['NS'].unique())\n",
    "    )\n",
    "else:\n",
    "    missing_EW_NS = None\n",
    "\n",
    "# Print the missing values of EW and NS\n",
    "print(\"Missing values of EW in test data:\", missing_EW)\n",
    "print(\"Missing values of NS in test data:\", missing_NS)\n",
    "print(\"Values of EW not present in NS:\", missing_EW_NS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numerical data\n",
    "le_EW = LabelEncoder()\n",
    "le_NS = LabelEncoder()\n",
    "\n",
    "# Encode the 'EW' and 'NS' columns\n",
    "train_data['EW_encoded'] = le_EW.fit_transform(train_data['EW'])\n",
    "train_data['NS_encoded'] = le_NS.fit_transform(train_data['NS'])\n",
    "\n",
    "# Define the Random Forest model for EW\n",
    "model_EW = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Fit the model to the training data for EW\n",
    "model_EW.fit(train_data[updated_feature_cols], train_data['EW_encoded'])\n",
    "\n",
    "# Define the Random Forest model for NS\n",
    "model_NS = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# Fit the model to the training data for NS\n",
    "model_NS.fit(train_data[updated_feature_cols], train_data['NS_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time Index</th>\n",
       "      <th>ObjectID</th>\n",
       "      <th>EW</th>\n",
       "      <th>Predicted_EW</th>\n",
       "      <th>NS</th>\n",
       "      <th>Predicted_NS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-HK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "      <td>SS-NK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time Index  ObjectID     EW Predicted_EW     NS Predicted_NS\n",
       "0           0         1  SS-HK        SS-HK  SS-NK        SS-NK\n",
       "1           1         1  SS-HK        SS-HK  SS-NK        SS-NK\n",
       "2           2         1  SS-HK        SS-HK  SS-NK        SS-NK\n",
       "0           0         2  SS-NK        SS-NK  SS-NK        SS-NK\n",
       "1           1         2  SS-NK        SS-NK  SS-NK        SS-NK\n",
       "2           2         2  SS-NK        SS-NK  SS-NK        SS-NK"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the training data for EW\n",
    "train_data['Predicted_EW'] = le_EW.inverse_transform(\n",
    "    model_EW.predict(train_data[updated_feature_cols])\n",
    ")\n",
    "\n",
    "# Make predictions on the validation data for NS\n",
    "train_data['Predicted_NS'] = le_NS.inverse_transform(\n",
    "    model_NS.predict(train_data[updated_feature_cols])\n",
    ")\n",
    "\n",
    "# Print the first few rows of the test data with predictions for both EW and NS\n",
    "train_data[['Time Index', 'ObjectID', 'EW', \n",
    "            'Predicted_EW', 'NS', 'Predicted_NS']].groupby('ObjectID').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.valid_ratio > 0:\n",
    "    # Make predictions on the validation data for EW\n",
    "    valid_data['Predicted_EW'] = le_EW.inverse_transform(\n",
    "        model_EW.predict(valid_data[updated_feature_cols])\n",
    "    )\n",
    "\n",
    "    # Make predictions on the validation data for NS\n",
    "    valid_data['Predicted_NS'] = le_NS.inverse_transform(\n",
    "        model_NS.predict(valid_data[updated_feature_cols])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classifier_output(classifier_output):\n",
    "    # Split the 'Predicted_EW' and 'Predicted_NS' columns into 'Node' and 'Type' columns\n",
    "    ew_df = classifier_output[['Time Index', 'ObjectID', 'Predicted_EW']].copy()\n",
    "    ew_df[['Node', 'Type']] = ew_df['Predicted_EW'].str.split('-', expand=True)\n",
    "    ew_df['Direction'] = 'EW'\n",
    "    ew_df.drop(columns=['Predicted_EW'], inplace=True)\n",
    "\n",
    "    ns_df = classifier_output[['Time Index', 'ObjectID', 'Predicted_NS']].copy()\n",
    "    ns_df[['Node', 'Type']] = ns_df['Predicted_NS'].str.split('-', expand=True)\n",
    "    ns_df['Direction'] = 'NS'\n",
    "    ns_df.drop(columns=['Predicted_NS'], inplace=True)\n",
    "\n",
    "    # Concatenate the processed EW and NS dataframes\n",
    "    final_df = pd.concat([ew_df, ns_df], ignore_index=True)\n",
    "\n",
    "    # Sort dataframe based on 'ObjectID', 'Direction' and 'Time Index'\n",
    "    final_df.sort_values(['ObjectID', 'Direction', 'Time Index'], inplace=True)\n",
    "\n",
    "    # Apply the function to each group of rows with the same 'ObjectID' and 'Direction'\n",
    "    groups = final_df.groupby(['ObjectID', 'Direction'])\n",
    "    keep = groups[['Node', 'Type']].apply(lambda group: group.shift() != group).any(axis=1)\n",
    "\n",
    "    # Filter the DataFrame to keep only the rows we're interested in\n",
    "    keep.index = final_df.index\n",
    "    final_df = final_df[keep]\n",
    "\n",
    "    # Reset the index and reorder the columns\n",
    "    final_df = final_df.reset_index(drop=True)\n",
    "    final_df = final_df[['ObjectID', 'Time Index', 'Direction', 'Node', 'Type']]\n",
    "    final_df = final_df.sort_values(['ObjectID', 'Time Index', 'Direction'])\n",
    "\n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the train set: 1.00\n",
      "Recall for the train set: 0.73\n",
      "F2 for the train set: 0.77\n",
      "RMSE for the train set: 0.00\n"
     ]
    }
   ],
   "source": [
    "train_results = convert_classifier_output(train_data)\n",
    "evaluator = NodeDetectionEvaluator(ground_truth_train, \n",
    "                                   train_results, \n",
    "                                   config.evaluation_tolerance)\n",
    "precision, recall, f2, rmse = evaluator.score()\n",
    "print(f'Precision for the train set: {precision:.2f}')\n",
    "print(f'Recall for the train set: {recall:.2f}')\n",
    "print(f'F2 for the train set: {f2:.2f}')\n",
    "print(f'RMSE for the train set: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total true positives: 8\n",
      "Total false positives: 0\n",
      "Total false negatives: 3\n"
     ]
    }
   ],
   "source": [
    "# Loop over the Object IDs in the training set and call the evaluation\n",
    "# function for each object and aggregate the results\n",
    "total_tp = 0\n",
    "total_fp = 0\n",
    "total_fn = 0\n",
    "for oid in train_data['ObjectID'].unique():\n",
    "    tp, fp, fn, gt_object, p_object = evaluator.evaluate(oid)\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "\n",
    "print(f'Total true positives: {total_tp}')\n",
    "print(f'Total false positives: {total_fp}')\n",
    "print(f'Total false negatives: {total_fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the validation set: 0.01\n",
      "Recall for the validation set: 0.25\n",
      "F2 for the validation set: 0.06\n",
      "RMSE for the validation set: 0.00\n"
     ]
    }
   ],
   "source": [
    "if config.valid_ratio > 0:\n",
    "    valid_results = convert_classifier_output(valid_data)\n",
    "    evaluator = NodeDetectionEvaluator(ground_truth_valid, valid_results,  \n",
    "                                         config.evaluation_tolerance)\n",
    "precision, recall, f2, rmse = evaluator.score()\n",
    "print(f'Precision for the validation set: {precision:.2f}')\n",
    "print(f'Recall for the validation set: {recall:.2f}')\n",
    "print(f'F2 for the validation set: {f2:.2f}')\n",
    "print(f'RMSE for the validation set: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/gbnws0ns4_q7pwh1hyzy5sdc0000gn/T/ipykernel_46526/3360359639.py:53: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  merged_data.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObjectID</th>\n",
       "      <th>Time Index</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Node</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>EW</td>\n",
       "      <td>SS</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NS</td>\n",
       "      <td>IK</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NS</td>\n",
       "      <td>SS</td>\n",
       "      <td>NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>NS</td>\n",
       "      <td>IK</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>147</td>\n",
       "      <td>NS</td>\n",
       "      <td>SS</td>\n",
       "      <td>NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>4</td>\n",
       "      <td>1845</td>\n",
       "      <td>NS</td>\n",
       "      <td>IK</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>4</td>\n",
       "      <td>1856</td>\n",
       "      <td>NS</td>\n",
       "      <td>SS</td>\n",
       "      <td>NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>4</td>\n",
       "      <td>1857</td>\n",
       "      <td>NS</td>\n",
       "      <td>IK</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>4</td>\n",
       "      <td>1868</td>\n",
       "      <td>NS</td>\n",
       "      <td>SS</td>\n",
       "      <td>NK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>4</td>\n",
       "      <td>1869</td>\n",
       "      <td>NS</td>\n",
       "      <td>IK</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ObjectID  Time Index Direction Node Type\n",
       "0           3           0        EW   SS   HK\n",
       "1           3           0        NS   IK   HK\n",
       "2           3           3        NS   SS   NK\n",
       "3           3         146        NS   IK   HK\n",
       "4           3         147        NS   SS   NK\n",
       "..        ...         ...       ...  ...  ...\n",
       "237         4        1845        NS   IK   HK\n",
       "238         4        1856        NS   SS   NK\n",
       "239         4        1857        NS   IK   HK\n",
       "240         4        1868        NS   SS   NK\n",
       "241         4        1869        NS   IK   HK\n",
       "\n",
       "[242 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dir = config.challenge_dir / \"test_data\"\n",
    "\n",
    "test_data, _ = prepare_data(test_data_dir, feature_cols, \n",
    "                            lag_steps=config.lag_steps)\n",
    "\n",
    "# Make predictions on the test data for EW\n",
    "test_data['Predicted_EW'] = le_EW.inverse_transform(\n",
    "    model_EW.predict(test_data[updated_feature_cols])\n",
    ")\n",
    "\n",
    "# Make predictions on the test data for NS\n",
    "test_data['Predicted_NS'] = le_NS.inverse_transform(\n",
    "    model_NS.predict(test_data[updated_feature_cols])\n",
    ")\n",
    "\n",
    "# save the predictions to a csv file\n",
    "test_data.to_csv(config.challenge_dir / 'baseline_results.csv', index=False)\n",
    "\n",
    "# Print the first few rows of the test data with predictions for both EW and NS\n",
    "test_results = convert_classifier_output(test_data)\n",
    "test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for the validation set: 0.00\n",
      "Recall for the validation set: 0.07\n",
      "F2 for the validation set: 0.02\n",
      "RMSE for the validation set: 0.00\n"
     ]
    }
   ],
   "source": [
    "ground_truth_test = pd.read_csv(config.challenge_dir / 'ground_truth_test.csv')\n",
    "evaluator = NodeDetectionEvaluator(ground_truth_test, test_results,\n",
    "                                         config.evaluation_tolerance)\n",
    "precision, recall, f2, rmse = evaluator.score()\n",
    "print(f'Precision for the validation set: {precision:.2f}')\n",
    "print(f'Recall for the validation set: {recall:.2f}')\n",
    "print(f'F2 for the validation set: {f2:.2f}')\n",
    "print(f'RMSE for the validation set: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test results to a csv file to be submitted to the challenge\n",
    "test_results.to_csv(config.challenge_dir / 'baseline_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table comparing results for the train, validation, and test sets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
